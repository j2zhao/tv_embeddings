{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9344ce3-076b-4028-b2f9-0439750a14ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tablevault.core import TableVault\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bccf777-bd77-481e-8b8a-8c1292e0dc0e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Setup Initial Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc437a0-83c0-4855-b6de-a55b95534723",
   "metadata": {},
   "outputs": [],
   "source": [
    "tablevault = TableVault(\"litsearch-tables\",\n",
    "                        \"jinjin\", \n",
    "                        description=\"trying tablevault for the first time on a real project!\", \n",
    "                        create = True,\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e4ff60-3906-43bc-8a8e-83eddf45a570",
   "metadata": {},
   "outputs": [],
   "source": [
    "tablevault.copy_files(file_dir=\"./code_functions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b6b51c-a723-4bce-9880-0b30a1159ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tablevault.setup_table(\"scientific_papers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5780d33-f087-4db7-8d57-439d6af0f034",
   "metadata": {},
   "outputs": [],
   "source": [
    "tablevault.setup_table(\"scientific_queries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8e99d3-b4ca-4497-8019-66b2975b3e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tablevault.setup_table(\"gritlm_base_embeddings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1826e7ed-0139-4dda-96b6-3942fafde722",
   "metadata": {},
   "outputs": [],
   "source": [
    "tablevault.setup_table(\"gritlm_base_embeddings_results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aca2675-81f0-4cb0-9c2a-1560539f9807",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = \"./tv_specifications\"\n",
    "for dir_ in os.listdir(base_dir):\n",
    "    print(dir_)\n",
    "    full_dir_ = os.path.join(base_dir, dir_)\n",
    "    if os.path.isdir(full_dir_) and not dir_.startswith(\".\"):\n",
    "        print(full_dir_)\n",
    "        tablevault.copy_files(full_dir_, dir_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a572741c-f156-49a0-9f38-0bf0a6d1ac4d",
   "metadata": {},
   "source": [
    "# Setup Pre-existing TableVault"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef4d5ea1-aa52-42d8-89a0-024ecfcbbfe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tablevault = TableVault(\"litsearch-tables\",\n",
    "                        \"jinjin\",\n",
    "                       )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d84e772-f69b-41e4-8e29-a14e7e3b0907",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Fetch Datasets From LitSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e30a8f0-bde8-41a1-86ec-6bf90632670e",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_id = tablevault.generate_process_id()\n",
    "process_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "937a8eab-c1c8-4255-a054-a9bf75eb406a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tablevault.setup_temp_instance(\"scientific_papers\", builder_names=[\"gen_scientific_papers\"], execute=True, process_id=process_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2940dd-3653-45e8-818f-bb3d1022ac18",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_id = tablevault.generate_process_id()\n",
    "process_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae7d475-87d9-437e-bebc-e4c4799da6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tablevault.setup_temp_instance(\"scientific_queries\", builder_names=[\"gen_scientific_queries\"], execute=True, process_id=process_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f630fa6-472e-430f-b31c-e6aaa382fa3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = tablevault.get_table(\"scientific_papers\", rows = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b9b7363-e8c8-4fff-8bf3-6daa14a01801",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'PHENAKI: VARIABLE LENGTH VIDEO GENERATION FROM OPEN DOMAIN TEXTUAL DESCRIPTIONS\\nWe present Phenaki, a model capable of realistic video synthesis, given a sequence of textual prompts. Generating videos from text is particularly challenging due to the computational cost, limited quantities of high quality text-video data and variable length of videos. To address these issues, we introduce a new model for learning video representation which compresses the video to a small representation of discrete tokens. This tokenizer uses causal attention in time, which allows it to work with variable-length videos. To generate video tokens from text we are using a bidirectional masked transformer conditioned on pre-computed text tokens. The generated video tokens are subsequently de-tokenized to create the actual video. To address data issues, we demonstrate how joint training on a large corpus of image-text pairs as well as a smaller number of video-text examples can result in generalization beyond what is available in the video datasets. Compared to the previous video generation methods, Phenaki can generate arbitrary long videos conditioned on a sequence of prompts (i.e. time variable text or a story) in open domain. To the best of our knowledge, this is the first time a paper studies generating videos from time variable prompts. In addition, compared to the perframe baselines, the proposed video encoder-decoder computes fewer tokens per video but results in better spatio-temporal consistency. â€¡ Equal contribution.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"full_paper\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d0f33353-a72a-43a4-a58c-d4fa41d44ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = tablevault.get_table(\"scientific_queries\", rows = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e51d3642-2788-4440-b3cf-7e1e81e8eecc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>query</th>\n",
       "      <th>query_set</th>\n",
       "      <th>specificity</th>\n",
       "      <th>quality</th>\n",
       "      <th>paperids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Are there any research papers on methods to co...</td>\n",
       "      <td>inline_acl</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>[202719327]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Are there any resources available for translat...</td>\n",
       "      <td>inline_acl</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>[227231792]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Are there any studies that explore post-hoc te...</td>\n",
       "      <td>inline_acl</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>[226254579 204976362]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Are there any tools or studies that have focus...</td>\n",
       "      <td>inline_acl</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>[10961392 12160022]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Are there papers that propose contextualized c...</td>\n",
       "      <td>inline_acl</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>[233296182]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                              query   query_set  \\\n",
       "0      0  Are there any research papers on methods to co...  inline_acl   \n",
       "1      1  Are there any resources available for translat...  inline_acl   \n",
       "2      2  Are there any studies that explore post-hoc te...  inline_acl   \n",
       "3      3  Are there any tools or studies that have focus...  inline_acl   \n",
       "4      4  Are there papers that propose contextualized c...  inline_acl   \n",
       "\n",
       "  specificity quality               paperids  \n",
       "0           0       2            [202719327]  \n",
       "1           1       2            [227231792]  \n",
       "2           0       2  [226254579 204976362]  \n",
       "3           1       2    [10961392 12160022]  \n",
       "4           1       2            [233296182]  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb652c0f-66e3-4eea-8c6e-758ea2549313",
   "metadata": {},
   "source": [
    "# Compute Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "01760aea-365d-4a20-b08d-1ac5e4d15628",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0a5bbdcb-fe14-41d0-a4e1-08efd802aabd'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_id = tablevault.generate_process_id()\n",
    "process_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "85eaa861-a453-4936-849d-73308e38be0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tablevault._operations._meta_operations:Start execution execute_instance: 0a5bbdcb-fe14-41d0-a4e1-08efd802aabd\n",
      "INFO:tablevault._operations._meta_operations:Start execution execute_instance_inner: 0a5bbdcb-fe14-41d0-a4e1-08efd802aabd_bfd50c19-49d8-4364-b53f-46ecbd8d4b9c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:accelerate.utils.modeling:We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a336944fb5dd4a6a8e1abc12298fd583",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:accelerate.big_modeling:Some parameters are on the meta device because they were offloaded to the cpu.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created GritLM: torch.bfloat16 dtype, mean pool, embedding mode, bbcc attn\n",
      "cuda\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 160.00 MiB. GPU 0 has a total capacity of 10.57 GiB of which 144.19 MiB is free. Including non-PyTorch memory, this process has 10.42 GiB memory in use. Of the allocated memory 10.03 GiB is allocated by PyTorch, and 209.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOutOfMemoryError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# tablevault.setup_temp_instance(\"gritlm_base_embeddings\", builder_names=[\"gen_gritlm_base_embeddings\", \"get_embeddings\"], execute=True,\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m#                               process_id=process_id)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[43mtablevault\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute_instance\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgritlm_base_embeddings\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocess_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprocess_id\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/jinjin-projects/tablevault/tablevault/tablevault/core.py:297\u001b[39m, in \u001b[36mTableVault.execute_instance\u001b[39m\u001b[34m(self, table_name, version, force_execute, process_id, background)\u001b[39m\n\u001b[32m    271\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mexecute_instance\u001b[39m(\n\u001b[32m    272\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    273\u001b[39m     table_name: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    277\u001b[39m     background: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    278\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    279\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    280\u001b[39m \u001b[33;03m    Materialize a table instance from YAML prompts.\u001b[39;00m\n\u001b[32m    281\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    295\u001b[39m \u001b[33;03m        background process. Defaults to False.\u001b[39;00m\n\u001b[32m    296\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m297\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_vault_operations\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute_instance\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    298\u001b[39m \u001b[43m        \u001b[49m\u001b[43mauthor\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mauthor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    299\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtable_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtable_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    300\u001b[39m \u001b[43m        \u001b[49m\u001b[43mversion\u001b[49m\u001b[43m=\u001b[49m\u001b[43mversion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    301\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforce_execute\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_execute\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    302\u001b[39m \u001b[43m        \u001b[49m\u001b[43mprocess_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprocess_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    303\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdb_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdb_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    304\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbackground\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbackground\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    305\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/jinjin-projects/tablevault/tablevault/tablevault/_vault_operations.py:558\u001b[39m, in \u001b[36mexecute_instance\u001b[39m\u001b[34m(author, table_name, version, force_execute, process_id, db_dir, background)\u001b[39m\n\u001b[32m    544\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mexecute_instance\u001b[39m(\n\u001b[32m    545\u001b[39m     author: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m    546\u001b[39m     table_name: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    551\u001b[39m     background: \u001b[38;5;28mbool\u001b[39m,\n\u001b[32m    552\u001b[39m ):\n\u001b[32m    553\u001b[39m     setup_kwargs = {\n\u001b[32m    554\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mtable_name\u001b[39m\u001b[33m\"\u001b[39m: table_name,\n\u001b[32m    555\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mversion\u001b[39m\u001b[33m\"\u001b[39m: version,\n\u001b[32m    556\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mforce_execute\u001b[39m\u001b[33m\"\u001b[39m: force_execute,\n\u001b[32m    557\u001b[39m     }\n\u001b[32m--> \u001b[39m\u001b[32m558\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtablevault_operation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    559\u001b[39m \u001b[43m        \u001b[49m\u001b[43mauthor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    560\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconstants\u001b[49m\u001b[43m.\u001b[49m\u001b[43mEXECUTE_OP\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    561\u001b[39m \u001b[43m        \u001b[49m\u001b[43m_execute_instance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    562\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdb_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    563\u001b[39m \u001b[43m        \u001b[49m\u001b[43mprocess_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    564\u001b[39m \u001b[43m        \u001b[49m\u001b[43msetup_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    565\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbackground\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    566\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/jinjin-projects/tablevault/tablevault/tablevault/_operations/_meta_operations.py:130\u001b[39m, in \u001b[36mtablevault_operation\u001b[39m\u001b[34m(author, op_name, op_funct, db_dir, process_id, setup_kwargs, background)\u001b[39m\n\u001b[32m    128\u001b[39m logger.info(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mStart execution \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mop_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprocess_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    129\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m130\u001b[39m     \u001b[43mop_funct\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfunct_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    131\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m tv_errors.TableVaultError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    132\u001b[39m     error = (e.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m, \u001b[38;5;28mstr\u001b[39m(e))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/jinjin-projects/tablevault/tablevault/tablevault/_vault_operations.py:506\u001b[39m, in \u001b[36m_execute_instance\u001b[39m\u001b[34m(instance_id, perm_instance_id, table_name, top_builder_names, changed_columns, all_columns, external_deps, origin_id, origin_table, step_ids, process_id, db_metadata)\u001b[39m\n\u001b[32m    504\u001b[39m complete_steps = db_metadata.get_active_processes()[process_id].complete_steps\n\u001b[32m    505\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m step_ids[\u001b[32m0\u001b[39m] \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m complete_steps:\n\u001b[32m--> \u001b[39m\u001b[32m506\u001b[39m     \u001b[43mexecute_instance_inner\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    507\u001b[39m \u001b[43m        \u001b[49m\u001b[43mprocess_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    508\u001b[39m \u001b[43m        \u001b[49m\u001b[43minstance_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    509\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtable_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    510\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtop_builder_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    511\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchanged_columns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    512\u001b[39m \u001b[43m        \u001b[49m\u001b[43mall_columns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    513\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexternal_deps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    514\u001b[39m \u001b[43m        \u001b[49m\u001b[43morigin_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    515\u001b[39m \u001b[43m        \u001b[49m\u001b[43morigin_table\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    516\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstep_ids\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    517\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdb_metadata\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdb_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    518\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    519\u001b[39m     db_metadata.update_process_step(process_id, step_ids[\u001b[32m0\u001b[39m])\n\u001b[32m    520\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m step_ids[\u001b[32m1\u001b[39m] \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m complete_steps:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/jinjin-projects/tablevault/tablevault/tablevault/_vault_operations.py:480\u001b[39m, in \u001b[36mexecute_instance_inner\u001b[39m\u001b[34m(author, instance_id, table_name, top_builder_names, changed_columns, all_columns, external_deps, origin_id, origin_table, process_id, db_dir)\u001b[39m\n\u001b[32m    457\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mexecute_instance_inner\u001b[39m(\n\u001b[32m    458\u001b[39m     author: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m    459\u001b[39m     instance_id: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    468\u001b[39m     db_dir: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m    469\u001b[39m ):\n\u001b[32m    470\u001b[39m     setup_kwargs = {\n\u001b[32m    471\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33minstance_id\u001b[39m\u001b[33m\"\u001b[39m: instance_id,\n\u001b[32m    472\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mtable_name\u001b[39m\u001b[33m\"\u001b[39m: table_name,\n\u001b[32m   (...)\u001b[39m\u001b[32m    478\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33morigin_table\u001b[39m\u001b[33m\"\u001b[39m: origin_table,\n\u001b[32m    479\u001b[39m     }\n\u001b[32m--> \u001b[39m\u001b[32m480\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtablevault_operation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    481\u001b[39m \u001b[43m        \u001b[49m\u001b[43mauthor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    482\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconstants\u001b[49m\u001b[43m.\u001b[49m\u001b[43mEXECUTE_INNER_OP\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    483\u001b[39m \u001b[43m        \u001b[49m\u001b[43m_execute_instance_inner\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    484\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdb_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    485\u001b[39m \u001b[43m        \u001b[49m\u001b[43mprocess_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    486\u001b[39m \u001b[43m        \u001b[49m\u001b[43msetup_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    487\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/jinjin-projects/tablevault/tablevault/tablevault/_operations/_meta_operations.py:130\u001b[39m, in \u001b[36mtablevault_operation\u001b[39m\u001b[34m(author, op_name, op_funct, db_dir, process_id, setup_kwargs, background)\u001b[39m\n\u001b[32m    128\u001b[39m logger.info(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mStart execution \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mop_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprocess_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    129\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m130\u001b[39m     \u001b[43mop_funct\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfunct_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    131\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m tv_errors.TableVaultError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    132\u001b[39m     error = (e.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m, \u001b[38;5;28mstr\u001b[39m(e))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/jinjin-projects/tablevault/tablevault/tablevault/_vault_operations.py:442\u001b[39m, in \u001b[36m_execute_instance_inner\u001b[39m\u001b[34m(instance_id, table_name, top_builder_names, changed_columns, all_columns, external_deps, origin_id, origin_table, process_id, db_metadata)\u001b[39m\n\u001b[32m    430\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_execute_instance_inner\u001b[39m(\n\u001b[32m    431\u001b[39m     instance_id: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m    432\u001b[39m     table_name: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    440\u001b[39m     db_metadata: MetadataStore,\n\u001b[32m    441\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m442\u001b[39m     \u001b[43m_table_execution\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute_instance\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    443\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtable_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    444\u001b[39m \u001b[43m        \u001b[49m\u001b[43minstance_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    445\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtop_builder_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    446\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchanged_columns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    447\u001b[39m \u001b[43m        \u001b[49m\u001b[43mall_columns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    448\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexternal_deps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    449\u001b[39m \u001b[43m        \u001b[49m\u001b[43morigin_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    450\u001b[39m \u001b[43m        \u001b[49m\u001b[43morigin_table\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    451\u001b[39m \u001b[43m        \u001b[49m\u001b[43mprocess_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    452\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdb_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    453\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/jinjin-projects/tablevault/tablevault/tablevault/_operations/_table_execution.py:83\u001b[39m, in \u001b[36mexecute_instance\u001b[39m\u001b[34m(table_name, instance_id, top_builder_names, changed_columns, all_columns, external_deps, origin_id, origin_table, process_id, db_metadata)\u001b[39m\n\u001b[32m     79\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     80\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m update_rows \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mset\u001b[39m(builders[builder_name].changed_columns).issubset(\n\u001b[32m     81\u001b[39m         changed_columns\n\u001b[32m     82\u001b[39m     ):\n\u001b[32m---> \u001b[39m\u001b[32m83\u001b[39m         \u001b[43mbuilders\u001b[49m\u001b[43m[\u001b[49m\u001b[43mbuilder_name\u001b[49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     84\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcache\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minstance_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtable_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdb_metadata\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdb_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocess_id\u001b[49m\n\u001b[32m     85\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     86\u001b[39m db_metadata.update_process_step(process_id, builder_name)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/jinjin-projects/tablevault/tablevault/tablevault/col_builders/code_execution_builder_type.py:69\u001b[39m, in \u001b[36mCodeBuilder.execute\u001b[39m\u001b[34m(self, cache, instance_id, table_name, db_dir, process_id)\u001b[39m\n\u001b[32m     65\u001b[39m             table_operations.write_table(\n\u001b[32m     66\u001b[39m                 cache[constants.OUTPUT_SELF], instance_id, table_name, db_dir\n\u001b[32m     67\u001b[39m             )\n\u001b[32m     68\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m69\u001b[39m     results = \u001b[43m_execute_code_from_builder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     70\u001b[39m \u001b[43m        \u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunct\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minstance_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtable_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdb_dir\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     72\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m col, values \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m.changed_columns, results):\n\u001b[32m     73\u001b[39m         table_operations.update_column(\n\u001b[32m     74\u001b[39m             values, cache[constants.OUTPUT_SELF], col\n\u001b[32m     75\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/jinjin-projects/tablevault/tablevault/tablevault/col_builders/code_execution_builder_type.py:99\u001b[39m, in \u001b[36m_execute_code_from_builder\u001b[39m\u001b[34m(index, builder, funct, cache, instance_id, table_name, db_dir)\u001b[39m\n\u001b[32m     97\u001b[39m builder = builder.model_copy(deep=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     98\u001b[39m builder.transform_table_string(cache, instance_id, table_name, db_dir, index)\n\u001b[32m---> \u001b[39m\u001b[32m99\u001b[39m results = \u001b[43mfunct\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mbuilder\u001b[49m\u001b[43m.\u001b[49m\u001b[43marguments\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    100\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m builder.save_by_row:\n\u001b[32m    101\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m i, result \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(results):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<string>:13\u001b[39m, in \u001b[36mgenerate_embeddings\u001b[39m\u001b[34m(texts, raw_instruction)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/tv_embeddings_env/lib/python3.13/site-packages/torch/utils/_contextlib.py:116\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/tv_embeddings_env/lib/python3.13/site-packages/gritlm/gritlm.py:133\u001b[39m, in \u001b[36mGritLM.encode\u001b[39m\u001b[34m(self, sentences, batch_size, max_length, instruction, embed_instruction, get_cache, convert_to_tensor, recast, add_special_tokens, **kwargs)\u001b[39m\n\u001b[32m    131\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m get_cache:\n\u001b[32m    132\u001b[39m     inputs[\u001b[33m'\u001b[39m\u001b[33muse_cache\u001b[39m\u001b[33m'\u001b[39m] = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m133\u001b[39m outputs = \u001b[43m(\u001b[49m\n\u001b[32m    134\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43membedding_attr\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43membedding_attr\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\n\u001b[32m    135\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    136\u001b[39m last_hidden_state = outputs[\u001b[32m0\u001b[39m]\n\u001b[32m    137\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m get_cache:\n\u001b[32m    138\u001b[39m     \u001b[38;5;66;03m# Tuple of `tuple(torch.FloatTensor)` of length `config.n_layers`, with each tuple having 2 tensors of shape `(batch_size, num_heads, sequence_length, embed_size_per_head)`\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/tv_embeddings_env/lib/python3.13/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/tv_embeddings_env/lib/python3.13/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/tv_embeddings_env/lib/python3.13/site-packages/accelerate/hooks.py:175\u001b[39m, in \u001b[36madd_hook_to_module.<locals>.new_forward\u001b[39m\u001b[34m(module, *args, **kwargs)\u001b[39m\n\u001b[32m    173\u001b[39m         output = module._old_forward(*args, **kwargs)\n\u001b[32m    174\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m175\u001b[39m     output = \u001b[43mmodule\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    176\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m module._hf_hook.post_forward(module, output)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.cache/huggingface/modules/transformers_modules/GritLM/GritLM-7B/138192cc56441e22a92f37ca05bdfff64ec3d83f/modeling_gritlm7b.py:1064\u001b[39m, in \u001b[36mMistralModel.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, labels, instruction_lens, is_causal)\u001b[39m\n\u001b[32m   1053\u001b[39m     layer_outputs = \u001b[38;5;28mself\u001b[39m._gradient_checkpointing_func(\n\u001b[32m   1054\u001b[39m         decoder_layer.\u001b[34m__call__\u001b[39m,\n\u001b[32m   1055\u001b[39m         hidden_states,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1061\u001b[39m         is_causal,\n\u001b[32m   1062\u001b[39m     )\n\u001b[32m   1063\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1064\u001b[39m     layer_outputs = \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1065\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1066\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1067\u001b[39m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1068\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1069\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1070\u001b[39m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1071\u001b[39m \u001b[43m        \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_causal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1072\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1074\u001b[39m hidden_states = layer_outputs[\u001b[32m0\u001b[39m]\n\u001b[32m   1076\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/tv_embeddings_env/lib/python3.13/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/tv_embeddings_env/lib/python3.13/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/tv_embeddings_env/lib/python3.13/site-packages/accelerate/hooks.py:175\u001b[39m, in \u001b[36madd_hook_to_module.<locals>.new_forward\u001b[39m\u001b[34m(module, *args, **kwargs)\u001b[39m\n\u001b[32m    173\u001b[39m         output = module._old_forward(*args, **kwargs)\n\u001b[32m    174\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m175\u001b[39m     output = \u001b[43mmodule\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    176\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m module._hf_hook.post_forward(module, output)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.cache/huggingface/modules/transformers_modules/GritLM/GritLM-7B/138192cc56441e22a92f37ca05bdfff64ec3d83f/modeling_gritlm7b.py:763\u001b[39m, in \u001b[36mMistralDecoderLayer.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, is_causal, **kwargs)\u001b[39m\n\u001b[32m    760\u001b[39m hidden_states = \u001b[38;5;28mself\u001b[39m.input_layernorm(hidden_states)\n\u001b[32m    762\u001b[39m \u001b[38;5;66;03m# Self Attention\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m763\u001b[39m hidden_states, self_attn_weights, present_key_value = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mself_attn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    764\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    765\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    766\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    767\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    768\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    769\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    770\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_causal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    771\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    772\u001b[39m hidden_states = residual + hidden_states\n\u001b[32m    774\u001b[39m \u001b[38;5;66;03m# Fully Connected\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/tv_embeddings_env/lib/python3.13/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/tv_embeddings_env/lib/python3.13/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/tv_embeddings_env/lib/python3.13/site-packages/accelerate/hooks.py:175\u001b[39m, in \u001b[36madd_hook_to_module.<locals>.new_forward\u001b[39m\u001b[34m(module, *args, **kwargs)\u001b[39m\n\u001b[32m    173\u001b[39m         output = module._old_forward(*args, **kwargs)\n\u001b[32m    174\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m175\u001b[39m     output = \u001b[43mmodule\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    176\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m module._hf_hook.post_forward(module, output)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.cache/huggingface/modules/transformers_modules/GritLM/GritLM-7B/138192cc56441e22a92f37ca05bdfff64ec3d83f/modeling_gritlm7b.py:693\u001b[39m, in \u001b[36mMistralSdpaAttention.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, is_causal)\u001b[39m\n\u001b[32m    690\u001b[39m     key_states = key_states.contiguous()\n\u001b[32m    691\u001b[39m     value_states = value_states.contiguous()\n\u001b[32m--> \u001b[39m\u001b[32m693\u001b[39m attn_output = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfunctional\u001b[49m\u001b[43m.\u001b[49m\u001b[43mscaled_dot_product_attention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    694\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquery_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    695\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkey_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    696\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalue_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    697\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    698\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdropout_p\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mattention_dropout\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[32;43m0.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    699\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# The q_len > 1 is necessary to match with AttentionMaskConverter.to_causal_4d that does not create a causal mask in case q_len == 1.\u001b[39;49;00m\n\u001b[32m    700\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_causal\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mq_len\u001b[49m\u001b[43m \u001b[49m\u001b[43m>\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    701\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    703\u001b[39m attn_output = attn_output.transpose(\u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m).contiguous()\n\u001b[32m    704\u001b[39m attn_output = attn_output.reshape(bsz, q_len, \u001b[38;5;28mself\u001b[39m.hidden_size)\n",
      "\u001b[31mOutOfMemoryError\u001b[39m: CUDA out of memory. Tried to allocate 160.00 MiB. GPU 0 has a total capacity of 10.57 GiB of which 144.19 MiB is free. Including non-PyTorch memory, this process has 10.42 GiB memory in use. Of the allocated memory 10.03 GiB is allocated by PyTorch, and 209.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "# tablevault.setup_temp_instance(\"gritlm_base_embeddings\", builder_names=[\"gen_gritlm_base_embeddings\", \"get_embeddings\"], execute=True,\n",
    "#                               process_id=process_id)\n",
    "tablevault.execute_instance(\"gritlm_base_embeddings\", process_id=process_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de25d2b-2b0b-4484-8f3d-5ce9e2884af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tablevault.fetch_table()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
